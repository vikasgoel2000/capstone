library(tm)
library(RWeka)
library("NLP") 
library("openNLP")

twitter<-readLines("en_US.twitter.txt",encoding = "en_US",warn = FALSE)
blogs<-readLines("en_US.blogs.txt",encoding = "en_US",warn = FALSE)
news<-readLines("en_US.news.txt",encoding = "en_US",warn = FALSE)

merge<-c(blogs, news, twitter)

merge<-iconv(merge,,"ASCII")
merge<-na.omit(merge)
merge<-iconv(merge,,"UTF-8")

msample<-sample(merge,50000)
corpus = Corpus(VectorSource(msample))

corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus = tm_map(corpus, removePunctuation)
badwords <- VectorSource(readLines("badwords.txt"))
corpus = tm_map(corpus, removeWords, badwords)
corpus <- tm_map(corpus, stripWhitespace)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
corpus <- tm_map(corpus, trim)
corpus <- tm_map(corpus, PlainTextDocument)


rm(twitter)
rm(blogs)
rm(news)
rm(merge)
rm(msample)

corpusDF = data.frame(text=unlist(sapply(corpus, `[`, "content")), stringsAsFactors=FALSE)

twoWordToken = NGramTokenizer(corpusDF, Weka_control(min = 2, max = 2, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng2 <- as.data.frame(table(as.matrix(twoWordToken)),stringsAsFactors=FALSE)

threeWordToken = NGramTokenizer(corpusDF, Weka_control(min = 3, max = 3, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng3<-as.data.frame(table(as.matrix(threeWordToken)),stringsAsFactors=FALSE)


fourWordToken = NGramTokenizer(corpusDF, Weka_control(min = 4, max = 4, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng4<-as.data.frame(table(as.matrix(fourWordToken)),stringsAsFactors=FALSE)

fiveWordToken = NGramTokenizer(corpusDF, Weka_control(min = 5, max = 5, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng5<-as.data.frame(table(as.matrix(fiveWordToken)),stringsAsFactors=FALSE)



rm(corpus)
rm(corpusDF)
