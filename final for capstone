library(tm)
library(RWeka)
library("NLP") 
library("openNLP")

twitter<-readLines("en_US.twitter.txt",warn = FALSE)
blogs<-readLines("en_US.blogs.txt",warn = FALSE)
news<-readLines("en_US.news.txt",warn = FALSE)

merge<-c(blogs, news, twitter)

msample<-sample(merge,5000)
corpus = Corpus(VectorSource(msample))

corpus <- tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removePunctuation)

rm(twitter)
rm(blogs)
rm(news)
rm(merge)
rm(msample)

corpusDF = data.frame(text=unlist(sapply(corpus, `[`, "content")), stringsAsFactors=FALSE)

twoWordToken = NGramTokenizer(corpusDF, Weka_control(min = 2, max = 2, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng2 <- as.data.frame(table(as.matrix(twoWordToken)),stringsAsFactors=FALSE)

threeWordToken = NGramTokenizer(corpusDF, Weka_control(min = 3, max = 3, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng3<-as.data.frame(table(as.matrix(threeWordToken)),stringsAsFactors=FALSE)


fourWordToken = NGramTokenizer(corpusDF, Weka_control(min = 4, max = 4, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng4<-as.data.frame(table(as.matrix(fourWordToken)),stringsAsFactors=FALSE)

rm(corpusDF)

