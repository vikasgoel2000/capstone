library(tm)
library(RWeka)
library("NLP") 
library("openNLP")
library("stringi")

twitter<-readLines("en_US.twitter.txt",warn = FALSE)
blogs<-readLines("en_US.blogs.txt",warn = FALSE)
news<-readLines("en_US.news.txt",warn = FALSE)

merge<-c(blogs, news, twitter)

msample<-sample(merge,50000)
corpus = Corpus(VectorSource(msample))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, stripWhitespace)
corpus <- tm_map(corpus, content_transformer(function(x) gsub("i'", "I'", x)));
corpus <- tm_map(corpus, content_transformer(function(x) gsub(" i ", " I ", x)));
corpus <- tm_map(corpus, content_transformer(function(x) gsub("^i", "I", x)));
corpus <- tm_map(corpus, content_transformer(function(x) gsub("$i", "I", x)));
corpus <- tm_map(corpus, content_transformer(function(x) gsub("[^[:alnum:][:space:]']", "", x)));
corpus = tm_map(corpus, removePunctuation)


rm(merge)


corpusDF = data.frame(text=unlist(sapply(corpus, `[`, "content")), stringsAsFactors=FALSE)

twoWordToken = NGramTokenizer(corpusDF, Weka_control(min = 2, max = 2, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng2 <- as.data.frame(table(as.matrix(twoWordToken)),stringsAsFactors=FALSE)

threeWordToken = NGramTokenizer(corpusDF, Weka_control(min = 3, max = 3, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng3<-as.data.frame(table(as.matrix(threeWordToken)),stringsAsFactors=FALSE)


fourWordToken = NGramTokenizer(corpusDF, Weka_control(min = 4, max = 4, delimiters = " \\r\\n\\t.,;:\"()?!"))
ng4<-as.data.frame(table(as.matrix(fourWordToken)),stringsAsFactors=FALSE)
rm(corpus)
rm(corpusDF)
